server:
  port: 9005
  servlet:
    multipart:
      max-file-size: 2M
    context-path: /databank-datatask
  ReadTimeout: 30000
  ConnectTimeout: 30000
  eureka:
    enable: true
eureka:
  instance:
    #断开时间
    lease-expiration-duration-in-seconds: 30
    #心跳时间
    lease-renewal-interval-in-seconds: 10
    prefer-ip-address: true
    instance-id: ${spring.application.name}:${spring.cloud.client.ip-address}:${server.port}
  client:
    fetch-registry: true
    register-with-eureka: true
    service-url:
#      defaultZone: http://172.16.7.119:28761/eureka/
      defaultZone: http://localhost:8000/eureka/
spring:
#  application:
#    name: databank-datatask
  resources:
    add-mappings: false
  redis:
    host: 172.16.7.119
    port: 26379
  mvc:
    throw-exception-if-no-handler-found: true


#   bean在MongoTemplateConfig中注入,  不会默认加载
  data:
    mongodb:
      uri: mongodb://172.16.7.140:27017/datastation,mongodb://172.16.7.140:27017/flume
  datasource:
    name: databank_authorization
    url: jdbc:mysql://172.16.7.119:23306/databank_datatask?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&&allowMultiQueries=true
    username: root
    password: huitone2214
    # 使用druid数据源
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    filters: stat
    maxActive: 20
    initialSize: 1
    maxWait: 60000
    minIdle: 1
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: SELECT 1 FROM DUAL
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true
    maxOpenPreparedStatements: 20


mybatis:
  mapper-locations: classpath:mapper/*.xml #这里是mapper的配置文件
  type-aliases-package: com.htgx.databank.datatask.entity #这里是实体类的包
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    call-setters-on-nulls: true
#配置分页插件pagehelper
pagehelper:
  helperDialect: mysql
  reasonable: true
  supportMethodsArguments: true
  params: count=countSql
  
#redis配置
jedis :  
  pool :  
    host : 172.16.7.119 
    port : 26379
    config :  
      maxTotal: 100  
      maxIdle: 10  
      maxWaitMillis : 100000 
      
# Hystrix 配置
hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            # 熔断器超时时间，默认：1000/毫秒
            timeoutInMilliseconds: 15000
ribbon:
  ReadTimeout: 15000
  ConnectTimeout: 15000
  MaxAutoRetries: 1 #同一台实例最大重试次数,不包括首次调用
  MaxAutoRetriesNextServer: 1 #重试负载均衡其他的实例最大重试次数,不包括首次调用
  OkToRetryOnAllOperations: false  #是否所有操作都重
  
#自定义配置标签
customize:
   flumePath : /data/databank/flume/apache-flume-1.9.0-bin/conf
   fileUploadUrl : http://172.16.7.119:29009/databank-filemanagement/file/upload
   fileDownloadUrl : http://172.16.7.119:29009/databank-filemanagement/file/download
   flumeServiceIp: 172.16.7.131 #flume服务器ip 如未指定则默认此ip
   flumeProjectId: 0  #flume项目id 如未指定则默认此id
   sparkPath : /home/software/spark2.2
   sparkJarPath : /home/spark_jar
   bigDataEnv : 0 ## 大数据环境 0公司  1华为云
   flinkPath : /home/software/flink-
   flinkJarPath : /home/flink_jar
   yarnStr : 172.16.7.140:8032,172.16.7.141:8032
   
system: 
  taskExecutor:
    corePoolSize: 10
    maxPoolSize: 300
    queueCapacity: 5000
  demo: true
data:
  task:
    count: 57218
   
