server:
  port: 9004
  servlet:
    multipart:
      max-file-size: 2M
    context-path: /databank-metadata
  ReadTimeout: 30000
  ConnectTimeout: 30000
  eureka:
    enable: true
eureka:
  instance:
    #断开时间
    lease-expiration-duration-in-seconds: 30
    #心跳时间
    lease-renewal-interval-in-seconds: 10
    prefer-ip-address: true
    instance-id: ${spring.application.name}:${spring.cloud.client.ip-address}:${server.port}
  client:
    fetch-registry: true
    register-with-eureka: true
    service-url:
#      defaultZone: http://172.16.7.119:28761/eureka/
      defaultZone: http://localhost:8000/eureka/
spring:
  application:
    name: databank-metadata
  redis:
    host: 172.16.7.119
    port: 26379
  resources:
    add-mappings: false
  mvc:
    throw-exception-if-no-handler-found: true
  datasource:
    name: databank_authorization
    url: jdbc:mysql://172.16.7.119:23306/databank_metadata?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&&allowMultiQueries=true
    username: root
    password: huitone2214
    # 使用druid数据源
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    filters: stat
    maxActive: 20
    initialSize: 1
    maxWait: 60000
    minIdle: 1
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: SELECT 1 FROM DUAL
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true
    maxOpenPreparedStatements: 20
mybatis:
  mapper-locations: classpath:mapper/*.xml #这里是mapper的配置文件
  type-aliases-package: com.htgx.databank.dataMeta.entity #这里是实体类的包
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    call-setters-on-nulls: true
#配置分页插件pagehelper
pagehelper:
  helperDialect: mysql
  reasonable: true
  supportMethodsArguments: true
  params: count=countSql

#自定义配置标签
customize:
   fileUploadUrl : http://172.16.7.119:29009/databank-filemanagement/file/upload
   fileDownloadUrl : http://172.16.7.119:29009/databank-filemanagement/file/download
   fileDeleteUrl : http://172.16.7.119:29009/databank-filemanagement/file/delete
   bigDataEnv : 0 ## 大数据环境 0公司(cdh)  1华为云

#cdh数据库连接
cdh:
  url: jdbc:mysql://172.16.7.140:3306/cm?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&&allowMultiQueries=true
  username: root
  password: htgx123!@#

cm:
  yarnurl: http://172.16.7.143:7180/api/v16/clusters/Cluster%201/services/yarn/config
  refreshurl: http://172.16.7.143:7180/api/v16/clusters/Cluster%201/commands/poolsRefresh
  username: admin
  password: admin

#组件升级配置
component-upgrade:
  #组件升级接口服务地址
  server-url: http://172.16.7.119:28000/datastation-deploy-api/upgrade
  #升级完监听topic
  topic: datastation.deploy.flume
defaultToken: f66944ff-6968-4210-abc4-f537d7a21a4f
    
system: 
  taskExecutor:
    corePoolSize: 10
    maxPoolSize: 300
    queueCapacity: 5000
  demo: true
data:
  api:
    count: 100
    week: 12
    day: 1
  project:
    count: 145
    week: 12
    day: 1
  meta:
    source:
      count: 10000
      week: 12
    module:
      count: 1345667
      week: 24
    table:
     count: 12545
     week: 12
  task:
    top10: 2454656,24556,23055,22455,21455,13455,2345,2045,1345,987

